{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Seq2Seq Translation with Attention"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from fastai.text.all import *\n",
    "from utils import *"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "path = Config.config_path/\"giga-fren\"\n",
    "df = pd.read_csv(path/\"questions_easy.csv\")\n",
    "df[\"en\"] = df[\"en\"].apply(lambda x: x.lower())\n",
    "df[\"fr\"] = df[\"fr\"].apply(lambda x: x.lower())\n",
    "df.tail()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>fr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52326</th>\n",
       "      <td>what are the mechanisms for increasing women's participation?</td>\n",
       "      <td>quels sont les mécanismes susceptibles d’améliorer cette participation?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52327</th>\n",
       "      <td>why is it still pushed aside, silenced, or the subject of jokes?</td>\n",
       "      <td>pourquoi, aujourd'hui encore, écarte-t-on cette question, la passe-t-on sous silence ou en fait-on un sujet de plaisanterie?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52328</th>\n",
       "      <td>why should they not demote a judge who rules against the government, or send the judge to some remote backwater as a reward for contrariness?</td>\n",
       "      <td>pourquoi ne devraient-ils pas destituer un juge qui rend une décision défavorable au gouvernement ou l'envoyer en quelque région reculée parce qu'il les a contrariés?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52329</th>\n",
       "      <td>why is it that we have achieved judicial independence when others have a hard time even understanding it?</td>\n",
       "      <td>pourquoi avons-nous réussi à atteindre l'indépendance de la magistrature alors que d'autres ont encore de la difficulté à comprendre ce concept?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52330</th>\n",
       "      <td>what's inside introduction to sti did you know…?</td>\n",
       "      <td>contenu introduction aux its saviez-vous que…?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                  en  \\\n",
       "52326                                                                                  what are the mechanisms for increasing women's participation?   \n",
       "52327                                                                               why is it still pushed aside, silenced, or the subject of jokes?   \n",
       "52328  why should they not demote a judge who rules against the government, or send the judge to some remote backwater as a reward for contrariness?   \n",
       "52329                                      why is it that we have achieved judicial independence when others have a hard time even understanding it?   \n",
       "52330                                                                                               what's inside introduction to sti did you know…?   \n",
       "\n",
       "                                                                                                                                                                           fr  \n",
       "52326                                                                                                 quels sont les mécanismes susceptibles d’améliorer cette participation?  \n",
       "52327                                            pourquoi, aujourd'hui encore, écarte-t-on cette question, la passe-t-on sous silence ou en fait-on un sujet de plaisanterie?  \n",
       "52328  pourquoi ne devraient-ils pas destituer un juge qui rend une décision défavorable au gouvernement ou l'envoyer en quelque région reculée parce qu'il les a contrariés?  \n",
       "52329                        pourquoi avons-nous réussi à atteindre l'indépendance de la magistrature alors que d'autres ont encore de la difficulté à comprendre ce concept?  \n",
       "52330                                                                                                                          contenu introduction aux its saviez-vous que…?  "
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "sl = 30\n",
    "\n",
    "dls = DataBlock(\n",
    "    blocks=(TextBlock.from_df(\"fr\", tok=SpacyTokenizer(\"fr\"), seq_len=sl),\n",
    "            TextBlock.from_df(\"en\", tok=SpacyTokenizer(\"en\"), seq_len=sl)),\n",
    "    get_x=ColReader(\"text\"), get_y=ColReader(\"text\"),\n",
    "    splitter=RandomSplitter(0.1)\n",
    ").dataloaders(df, bs=64, num_workers=os.cpu_count(), seq_len=sl)\n",
    "dls.show_batch(max_n=3)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/anaconda/envs/fastai/lib/python3.8/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos dans un tel cas , où il s’ agit d ’ apprécier si un nom commercial a un fondement juridique antérieur à celui d ’ une marque aux fins de l’ article 16 , paragraphe 1 , troisième phrase , de l’ accord adpic , peut -on considérer comme décisif : i ) le fait que , dans l’ état où la marque est enregistrée et sa protection réclamée , le nom commercial ait été , du moins dans une certaine mesure , connu dans les milieux professionnels xxunk xxunk de l’ état concerné avant la date à laquelle l’ enregistrement de la marque y a été demandé ; ou que , dans les relations commerciales intéressant l’ état où la marque est xxunk ée et sa protection réclamée , le nom commercial ait été utilisé avant la date à laquelle l’ enregistrement de la marque a été demandé</td>\n",
       "      <td>xxbos when assessing , in such a case , whether a trade name has a legal basis prior to a trade mark for the purposes of the third sentence of article 16(1 ) of the trips agreement , may it thus be considered as decisive : ( i ) whether the trade name was well known at least to some extent among the relevant trade circles in the state in which the trade mark is registered and in which protection is sought for it , before the point in time at which registration of the trade mark was applied for in the state in question ; or whether the trade name was used in commerce directed to the state in which the trade mark is registered and in which protection is sought for it , before the point in time at which registration of the trade mark was applied for in the state in question ; or what other factor may decide whether the trade name is to be regarded as an existing prior right within the meaning of the third sentence of article 16(1 ) of the trips agreement ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xxbos quels types de délits en matière de propriété intellectuelle sont enregistrés en australie ( en particulier , quel est le volume de marchandises de contrefaçon et de marchandises pirates sur le marché ) et quel aspect des délits en matière de propriété intellectuelle a le plus d’ impact ( par exemple , la distribution à petite échelle , l’ implication du crime organisé , l’ importation des produits ou leur fabrication locale , la diffusion en ligne de musique , de films , d’ émissions xxunk ou de logiciels d’ entreprise ) ?</td>\n",
       "      <td>xxbos what kind of ip crime is affecting australia ( ie what is the volume of counterfeit / pirated goods on the market ) and what aspect of ip crime is xxunk the most ( eg small - scale market distribution , organised crime involvement , cross - border importation or domestic manufacture , online distribution of music , film , television and business software products ) ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xxbos deux questions xxunk le projet : quels changements sont nécessaires à l' école pour que la mise en oeuvre de pratiques et de xxunk xxunk parviennent à atteindre le double objectif de la réussite et de l' égalité ; et quels sont les obstacles et les possibilités actuels pour relier les besoins des parents et de la communauté aux résultats des recherches et aux meilleures pratiques quand il faut maximiser le potentiel d' apprentissage , les rôles de vie adulte et les perspectives de carrière des étudiants à risques ?</td>\n",
       "      <td>xxbos what changes need to happen for schools in the implementation of inclusive education philosophy and practice to achieve xxunk goals of excellence and equity ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "m = np.array([len(st.split(\" \")) for st in df.to_numpy()[:, 0]])\n",
    "np.where(m > 50)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([ 3514,  3571,  7127,  7381,  7382,  7469,  8196,  8205,  9277,\n",
       "         9343, 10073, 11388, 11671, 13900, 17602, 17605, 19245, 19935,\n",
       "        21893, 22414, 22475, 22476, 22478, 24131, 24314, 24389, 24611,\n",
       "        25905, 26362, 26365, 26372, 26373, 26983, 27535, 29495, 29643,\n",
       "        30264, 30508, 31297, 31643, 32052, 32192, 33303, 34690, 35244,\n",
       "        35413, 35794, 35799, 36506, 36624, 36706, 36790, 37142, 37635,\n",
       "        37749, 37945, 39059, 40286, 40344, 40462, 40466, 41088, 41691,\n",
       "        41716, 41948, 41983, 42512, 43437, 43628, 43727, 43730, 43731,\n",
       "        43732, 44374, 44532, 44676, 44806, 45098, 45310, 45441, 45565,\n",
       "        46404, 46481, 46967, 47242, 47442, 47506, 47596, 47654, 47743,\n",
       "        47797, 47910, 47934, 48381, 48625, 48905, 49375, 49777, 49914,\n",
       "        50031, 50035, 50694, 50869, 51484, 51838, 51939, 51987, 52294]),)"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "model_path = Config.config_path/\"models\"\n",
    "emb_enc = torch.load(model_path/\"fr_emb.pth\")\n",
    "emb_dec = torch.load(model_path/\"en_emb.pth\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "emb_dec"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Embedding(9112, 300, padding_idx=1)"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "def seq2seq_loss(out, targ, pad_idx=1):\n",
    "    bs, targ_len = targ.size()\n",
    "    _, out_len, vs = out.size()\n",
    "    if targ_len > out_len: out = F.pad(out, (0, 0, 0, targ_len - out_len, 0, 0), value=pad_idx)\n",
    "    if out_len > targ_len: targ = F.pad(targ, (0, out_len - targ_len, 0, 0), value=pad_idx)\n",
    "    return CrossEntropyLossFlat()(out, targ)\n",
    "\n",
    "\n",
    "def seq2seq_acc(out, targ, pad_idx=1):\n",
    "    bs, targ_len = targ.size()\n",
    "    _, out_len, vs = out.size()\n",
    "    if targ_len > out_len: out = F.pad(out, (0, 0, 0, targ_len - out_len, 0, 0), value=pad_idx)\n",
    "    if out_len > targ_len: targ = F.pad(targ, (0, out_len - targ_len, 0, 0), value=pad_idx)\n",
    "    out = out.argmax(2)\n",
    "    return (out == targ).float().mean()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "class NGram():\n",
    "    def __init__(self, ngram, max_n=5000): self.ngram,self.max_n = ngram,max_n\n",
    "    def __eq__(self, other):\n",
    "        if len(self.ngram) != len(other.ngram): return False\n",
    "        return np.all(np.array(self.ngram) == np.array(other.ngram))\n",
    "    def __hash__(self): return int(sum([o * self.max_n**i for i,o in enumerate(self.ngram)]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "def get_grams(x, n, max_n=5000):\n",
    "    return x if n==1 else [NGram(x[i:i+n], max_n=max_n) for i in range(len(x)-n+1)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "def get_correct_ngrams(pred, targ, n, max_n=5000):\n",
    "    pred_grams,targ_grams = get_grams(pred, n, max_n=max_n),get_grams(targ, n, max_n=max_n)\n",
    "    pred_cnt,targ_cnt = Counter(pred_grams),Counter(targ_grams)\n",
    "    return sum([min(c, targ_cnt[g]) for g,c in pred_cnt.items()]),len(pred_grams)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "class GetPreds:\n",
    "    def __init__(self, inputs, preds, targs):\n",
    "        self.inputs, self.preds, self.targs = inputs, preds, targs\n",
    "\n",
    "    def get_predictions(self, num, ignore_pad=False): \n",
    "        \"\"\":ignore_pad: Whether to ignore pad for predictions. Default: False\"\"\"\n",
    "        return (\n",
    "            itos(dls.vocab[0], self.inputs[num], join=True, ignore_pad=True),\n",
    "            itos(dls.vocab[1], self.targs[num], join=True, ignore_pad=True),\n",
    "            itos(dls.vocab[1], self.preds[num].argmax(1), join=True, ignore_pad=ignore_pad)\n",
    "        )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "class TeacherForcing(Callback):\n",
    "    def __init__(self, end_epoch, full_force_for=0): \n",
    "        self.fff = full_force_for - 1  # start counting from zero. \n",
    "        self.end_epoch = end_epoch\n",
    "    \n",
    "    def before_batch(self): \n",
    "        self.learn.xb = (self.x, self.y)\n",
    "\n",
    "    def before_epoch(self):\n",
    "        self.learn.model.pr_force = 1 - ((self.learn.epoch - self.fff) / (self.end_epoch - self.fff))\n",
    "        if self.learn.epoch <= self.fff: self.learn.model.pr_force = 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Implementing Attention"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "class Seq2SeqRNN_attn(Module):\n",
    "    def __init__(self, emb_enc, emb_dec, nh, out_sl, nl=2, bos_idx=0, pad_idx=1):\n",
    "        self.nl, self.nh, self.out_sl, self.pr_force = nl, nh, out_sl, 1\n",
    "        self.bos_idx, self.pad_idx = bos_idx, pad_idx\n",
    "        self.emb_enc, self.emb_dec = emb_enc, emb_dec\n",
    "        self.emb_sz_enc, self.emb_sz_dec = emb_enc.embedding_dim, emb_enc.embedding_dim\n",
    "        self.voc_sz_dec = emb_dec.num_embeddings\n",
    "\n",
    "        self.emb_enc_drop = nn.Dropout(0.15)\n",
    "        self.gru_enc = nn.GRU(self.emb_sz_enc, nh, num_layers=nl, dropout=0.25,\n",
    "                        batch_first=True, bidirectional=True)\n",
    "        self.out_enc = nn.Linear(2 * nh, self.emb_sz_dec, bias=False)\n",
    "\n",
    "        self.gru_dec = nn.GRU(self.emb_sz_dec + 2 * nh, self.emb_sz_dec, num_layers=nl,\n",
    "                        dropout=0.1, batch_first=True)\n",
    "        self.out_drop = nn.Dropout(0.35)\n",
    "        self.out = nn.Linear(self.emb_sz_dec, self.voc_sz_dec)\n",
    "        self.out.weight.data = self.emb_dec.weight.data\n",
    "\n",
    "        self.enc_att = nn.Linear(2 * nh, self.emb_sz_dec, bias=False)\n",
    "        self.hid_att = nn.Linear(self.emb_sz_dec, self.emb_sz_dec)\n",
    "        self.V = self.init_param(self.emb_sz_dec)\n",
    "\n",
    "    def encoder(self, bs, inp):\n",
    "        h = self.initHidden(bs)\n",
    "        emb = self.emb_enc_drop(self.emb_enc(inp))\n",
    "        enc_out, hid = self.gru_enc(emb, 2 * h)\n",
    "\n",
    "        pre_hid = hid.view(2, self.nl, bs, self.nh).permute(1, 2, 0, 3).contiguous()\n",
    "        pre_hid = pre_hid.view(self.nl, bs, 2 * self.nh)\n",
    "        hid = self.out_enc(pre_hid)\n",
    "\n",
    "        return hid, enc_out\n",
    "\n",
    "    def decoder(self, dec_inp, hid, enc_att, enc_out):\n",
    "        hid_att = self.hid_att(hid[-1])\n",
    "\n",
    "        # enc_out and hid through linear layers\n",
    "        u = torch.tanh(enc_att + hid_att[:, None])\n",
    "\n",
    "        # Learn importance each time step\n",
    "        attn_wgts = F.softmax(u @ self.V, 1)\n",
    "\n",
    "        # weighted average of enc_out (output at every time step)\n",
    "        ctx = (attn_wgts[..., None] * enc_out).sum(1)\n",
    "        emb = self.emb_dec(dec_inp)\n",
    "\n",
    "        # Concat decoder embed with context\n",
    "        outp, hid = self.gru_dec(torch.cat([emb, ctx], 1)[:, None], hid)\n",
    "        outp = self.out(self.out_drop(outp[:, 0]))\n",
    "        return hid, outp\n",
    "\n",
    "    def show(self, nm, v): \n",
    "        if False: print(f\"{nm}={v[nm].shape}\")\n",
    "\n",
    "    def forward(self, inp, targ=None):\n",
    "        bs, sl = inp.size()\n",
    "        hid, enc_out = self.encoder(bs, inp)\n",
    "        # self.show(\"hid\", vars())\n",
    "        dec_inp = inp.new_zeros(bs).long() + self.bos_idx\n",
    "        enc_att = self.enc_att(enc_out)\n",
    "\n",
    "        res = []\n",
    "\n",
    "        for i in range(self.out_sl):\n",
    "            hid, outp = self.decoder(dec_inp, hid, enc_att, enc_out)\n",
    "            res.append(outp)\n",
    "            dec_inp = outp.max(1)[1]\n",
    "            if (dec_inp==self.pad_idx).all(): break\n",
    "\n",
    "            if (targ is not None) and (random.random() < self.pr_force):\n",
    "                if i >= targ.shape[1]: continue\n",
    "                assert dec_inp.shape == targ[:, i].shape\n",
    "                dec_inp = targ[:, i]\n",
    "        \n",
    "        return torch.stack(res, dim=1)\n",
    "\n",
    "    def initHidden(self, bs): return one_param(self).new_zeros(2 * self.nl, bs, self.nh)\n",
    "    def init_param(self, *sz): return nn.Parameter(torch.randn(sz) / math.sqrt(sz[0]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "model = Seq2SeqRNN_attn(emb_enc, emb_dec, 256, 30)\n",
    "model"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Seq2SeqRNN_attn(\n",
       "  (emb_enc): Embedding(11600, 300, padding_idx=1)\n",
       "  (emb_dec): Embedding(9112, 300, padding_idx=1)\n",
       "  (emb_enc_drop): Dropout(p=0.15, inplace=False)\n",
       "  (gru_enc): GRU(300, 256, num_layers=2, batch_first=True, dropout=0.25, bidirectional=True)\n",
       "  (out_enc): Linear(in_features=512, out_features=300, bias=False)\n",
       "  (gru_dec): GRU(812, 300, num_layers=2, batch_first=True, dropout=0.1)\n",
       "  (out_drop): Dropout(p=0.35, inplace=False)\n",
       "  (out): Linear(in_features=300, out_features=9112, bias=True)\n",
       "  (enc_att): Linear(in_features=512, out_features=300, bias=False)\n",
       "  (hid_att): Linear(in_features=300, out_features=300, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "torch.cuda.empty_cache()\n",
    "learn = Learner(dls, model, loss_func=seq2seq_loss, \n",
    "            metrics=[seq2seq_acc, CorpusBLEUMetric(len(dls.vocab[1]))],\n",
    "            cbs=[TeacherForcing(30, 3)])\n",
    "learn.lr_find()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "SuggestedLRs(valley=tensor(0.0003))"
      ]
     },
     "metadata": {},
     "execution_count": 54
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "learn.fit_one_cycle(15, 3e-3)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>seq2seq_acc</th>\n",
       "      <th>corpus_bleu</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.274745</td>\n",
       "      <td>3.290447</td>\n",
       "      <td>0.550881</td>\n",
       "      <td>0.366174</td>\n",
       "      <td>02:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.696936</td>\n",
       "      <td>2.795808</td>\n",
       "      <td>0.604760</td>\n",
       "      <td>0.386262</td>\n",
       "      <td>02:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.403678</td>\n",
       "      <td>2.460868</td>\n",
       "      <td>0.640072</td>\n",
       "      <td>0.408413</td>\n",
       "      <td>02:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.003400</td>\n",
       "      <td>2.324944</td>\n",
       "      <td>0.651999</td>\n",
       "      <td>0.431581</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.225621</td>\n",
       "      <td>2.254841</td>\n",
       "      <td>0.659783</td>\n",
       "      <td>0.427665</td>\n",
       "      <td>02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.981703</td>\n",
       "      <td>2.263620</td>\n",
       "      <td>0.661931</td>\n",
       "      <td>0.433464</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.860337</td>\n",
       "      <td>2.396944</td>\n",
       "      <td>0.648175</td>\n",
       "      <td>0.417830</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.966225</td>\n",
       "      <td>2.274959</td>\n",
       "      <td>0.661903</td>\n",
       "      <td>0.440676</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.828020</td>\n",
       "      <td>2.370565</td>\n",
       "      <td>0.653450</td>\n",
       "      <td>0.431299</td>\n",
       "      <td>02:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.773579</td>\n",
       "      <td>2.422613</td>\n",
       "      <td>0.649914</td>\n",
       "      <td>0.433362</td>\n",
       "      <td>02:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.024141</td>\n",
       "      <td>2.519674</td>\n",
       "      <td>0.636507</td>\n",
       "      <td>0.424246</td>\n",
       "      <td>02:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.608306</td>\n",
       "      <td>2.515211</td>\n",
       "      <td>0.640341</td>\n",
       "      <td>0.428511</td>\n",
       "      <td>02:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.864239</td>\n",
       "      <td>2.626436</td>\n",
       "      <td>0.628741</td>\n",
       "      <td>0.421488</td>\n",
       "      <td>02:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.886644</td>\n",
       "      <td>2.737025</td>\n",
       "      <td>0.615172</td>\n",
       "      <td>0.410242</td>\n",
       "      <td>02:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.013999</td>\n",
       "      <td>2.858145</td>\n",
       "      <td>0.601201</td>\n",
       "      <td>0.401374</td>\n",
       "      <td>02:22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "inputs, preds, targs = learn.get_preds(with_input=True)\n",
    "p = GetPreds(inputs[0], preds, targs)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "It seems like this have 2 input features, and `inputs[0]` matches their english equivalent. One isn't sure that does `inputs[1]` represents here. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "p.get_predictions(700)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(\"xxbos quels étaient vos plans en cas d' échec au concours ?\",\n",
       " 'xxbos what were your plans if you were to be unsuccessful in the competition ?',\n",
       " 'xxbos what were your plans if you were to be unsuccessful in the competition ? xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad')"
      ]
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "p.get_predictions(701)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('xxbos quelles sont vos responsabilités en qualité de gestionnaire dans ce processus ?',\n",
       " 'xxbos what are you responsibilities as a manager in this process ?',\n",
       " 'xxbos what are your in as a manager in this process ? xxpad xxpad xxpad xxpad xxpad xxpad xxpad')"
      ]
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "p.get_predictions(4002)  # this is very funny"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(\"xxbos comment s' en passer ?\",\n",
       " 'xxbos what would we do without it ?',\n",
       " 'x x p a d')"
      ]
     },
     "metadata": {},
     "execution_count": 78
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "p.get_predictions(4010)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('xxbos quelle est votre priorité - la salubrité ou la nutrition ?',\n",
       " 'xxbos which is your priority - safety or nutrition ?',\n",
       " 'xxbos what is your priority safety food or nutrition ? xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad')"
      ]
     },
     "metadata": {},
     "execution_count": 79
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.2",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit ('fastai': conda)"
  },
  "interpreter": {
   "hash": "5aa457f694240ca52bec53eda6ed84b45efde55787bbd717cb0e138c3a892911"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}