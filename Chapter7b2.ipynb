{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Neural Text Generation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from seq2seq import *\n",
    "from fastai.text.all import *\n",
    "from utils import *\n",
    "\n",
    "path = Config.config_path/\"giga-fren\"\n",
    "model_path = Config.config_path/\"models\"\n",
    "emb_enc = torch.load(model_path/\"fr_emb.pth\")\n",
    "emb_dec = torch.load(model_path/\"en_emb.pth\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "class Seq2SeqRNN_attn(Module):\n",
    "    def __init__(self, emb_enc, emb_dec, nh, out_sl, nl=2, bos_idx=0, pad_idx=1):\n",
    "        self.nl, self.nh, self.out_sl, self.pr_force = nl, nh, out_sl, 1\n",
    "        self.bos_idx, self.pad_idx = bos_idx, pad_idx\n",
    "        self.emb_enc, self.emb_dec = emb_enc, emb_dec\n",
    "        self.emb_sz_enc, self.emb_sz_dec = emb_enc.embedding_dim, emb_enc.embedding_dim\n",
    "        self.voc_sz_dec = emb_dec.num_embeddings\n",
    "\n",
    "        self.emb_enc_drop = nn.Dropout(0.15)\n",
    "        self.gru_enc = nn.GRU(self.emb_sz_enc, nh, num_layers=nl, dropout=0.25,\n",
    "                        batch_first=True, bidirectional=True)\n",
    "        self.out_enc = nn.Linear(2 * nh, self.emb_sz_dec, bias=False)\n",
    "\n",
    "        self.gru_dec = nn.GRU(self.emb_sz_dec + 2 * nh, self.emb_sz_dec, num_layers=nl,\n",
    "                        dropout=0.1, batch_first=True)\n",
    "        self.out_drop = nn.Dropout(0.35)\n",
    "        self.out = nn.Linear(self.emb_sz_dec, self.voc_sz_dec)\n",
    "        self.out.weight.data = self.emb_dec.weight.data\n",
    "\n",
    "        self.enc_att = nn.Linear(2 * nh, self.emb_sz_dec, bias=False)\n",
    "        self.hid_att = nn.Linear(self.emb_sz_dec, self.emb_sz_dec)\n",
    "        self.V = self.init_param(self.emb_sz_dec)\n",
    "\n",
    "    def encoder(self, bs, inp):\n",
    "        h = self.initHidden(bs)\n",
    "        emb = self.emb_enc_drop(self.emb_enc(inp))\n",
    "        enc_out, hid = self.gru_enc(emb, 2 * h)\n",
    "\n",
    "        pre_hid = hid.view(2, self.nl, bs, self.nh).permute(1, 2, 0, 3).contiguous()\n",
    "        pre_hid = pre_hid.view(self.nl, bs, 2 * self.nh)\n",
    "        hid = self.out_enc(pre_hid)\n",
    "\n",
    "        return hid, enc_out\n",
    "\n",
    "    def decoder(self, dec_inp, hid, enc_att, enc_out):\n",
    "        hid_att = self.hid_att(hid[-1])\n",
    "\n",
    "        # enc_out and hid through linear layers\n",
    "        u = torch.tanh(enc_att + hid_att[:, None])\n",
    "\n",
    "        # Learn importance each time step\n",
    "        attn_wgts = F.softmax(u @ self.V, 1)\n",
    "\n",
    "        # weighted average of enc_out (output at every time step)\n",
    "        ctx = (attn_wgts[..., None] * enc_out).sum(1)\n",
    "        emb = self.emb_dec(dec_inp)\n",
    "\n",
    "        # Concat decoder embed with context\n",
    "        outp, hid = self.gru_dec(torch.cat([emb, ctx], 1)[:, None], hid)\n",
    "        outp = self.out(self.out_drop(outp[:, 0]))\n",
    "        return hid, outp\n",
    "\n",
    "    def show(self, nm, v): \n",
    "        if False: print(f\"{nm}={v[nm].shape}\")\n",
    "\n",
    "    def forward(self, inp, targ=None):\n",
    "        bs, sl = inp.size()\n",
    "        hid, enc_out = self.encoder(bs, inp)\n",
    "        # self.show(\"hid\", vars())\n",
    "        dec_inp = inp.new_zeros(bs).long() + self.bos_idx\n",
    "        enc_att = self.enc_att(enc_out)\n",
    "\n",
    "        res = []\n",
    "\n",
    "        for i in range(self.out_sl):\n",
    "            hid, outp = self.decoder(dec_inp, hid, enc_att, enc_out)\n",
    "            res.append(outp)\n",
    "            dec_inp = outp.max(1)[1]\n",
    "            if (dec_inp==self.pad_idx).all(): break\n",
    "\n",
    "            if (targ is not None) and (random.random() < self.pr_force):\n",
    "                if i >= targ.shape[1]: continue\n",
    "                assert dec_inp.shape == targ[:, i].shape\n",
    "                dec_inp = targ[:, i]\n",
    "        \n",
    "        return torch.stack(res, dim=1)\n",
    "\n",
    "    def initHidden(self, bs): return one_param(self).new_zeros(2 * self.nl, bs, self.nh)\n",
    "    def init_param(self, *sz): return nn.Parameter(torch.randn(sz) / math.sqrt(sz[0]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "df = pd.read_csv(path/\"questions_easy.csv\")\n",
    "df[\"en\"] = df[\"en\"].apply(lambda x: x.lower())\n",
    "df[\"fr\"] = df[\"fr\"].apply(lambda x: x.lower())\n",
    "df.tail()\n",
    "\n",
    "sl = 30  # try longer or shorter? \n",
    "\n",
    "dls = DataBlock(\n",
    "    blocks=(TextBlock.from_df(\"fr\", tok=SpacyTokenizer(\"fr\"), seq_len=sl),\n",
    "            TextBlock.from_df(\"en\", tok=SpacyTokenizer(\"en\"), seq_len=sl)),\n",
    "    get_x=ColReader(\"text\"), get_y=ColReader(\"text\"),\n",
    "    splitter=RandomSplitter(0.1)\n",
    ").dataloaders(df, bs=64, num_workers=os.cpu_count(), seq_len=sl)\n",
    "dls.show_batch(max_n=3)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/anaconda/envs/fastai/lib/python3.8/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos dans un tel cas , où il s’ agit d ’ apprécier si un nom commercial a un fondement juridique antérieur à celui d ’ une marque aux fins de l’ article 16 , paragraphe 1 , troisième phrase , de l’ accord adpic , peut -on considérer comme décisif : i ) le fait que , dans l’ état où la marque est enregistrée et sa protection réclamée , le nom commercial ait été , du moins dans une certaine mesure , connu dans les milieux professionnels xxunk xxunk de l’ état concerné avant la date à laquelle l’ enregistrement de la marque y a été demandé ; ou que , dans les relations commerciales intéressant l’ état où la marque est xxunk ée et sa protection réclamée , le nom commercial ait été utilisé avant la date à laquelle l’ enregistrement de la marque a été demandé</td>\n",
       "      <td>xxbos when assessing , in such a case , whether a trade name has a legal basis prior to a trade mark for the purposes of the third sentence of article 16(1 ) of the trips agreement , may it thus be considered as decisive : ( i ) whether the trade name was well known at least to some extent among the relevant trade circles in the state in which the trade mark is registered and in which protection is sought for it , before the point in time at which registration of the trade mark was applied for in the state in question ; or whether the trade name was used in commerce directed to the state in which the trade mark is registered and in which protection is sought for it , before the point in time at which registration of the trade mark was applied for in the state in question ; or what other factor may decide whether the trade name is to be regarded as an existing prior right within the meaning of the third sentence of article 16(1 ) of the trips agreement ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xxbos on lui avait alors demandé : « lorsque le temps presse , par exemple , au début de décembre , on a annoncé à ces deux unités , le royal canadian xxunk ( xxunk ) et le royal canadian xxunk ( xxunk ) , qu' elles feraient partie d' un xxunk tactique et qu' elles n avaient que quelques jours pour se préparer , n' est -ce pas là une situation où un officier supérieur comme vous devrait vérifier l' état de préparation opérationnelle de l' ensemble des troupes , pour déterminer si tous les membres de l' unité peuvent travailler ensemble ?</td>\n",
       "      <td>xxbos when asked \" if you have a very xxunk time line ; that is , in early december these two units , the royal canadian regiment ( xxunk ) and the royal canadian xxunk ( xxunk ) , are being told they are now going to be part of the battle group and they have literally days in which to prepare , is that not a situation where a superior officer like yourself should be deciding about operational readiness of the whole configuration , whether the whole unit can work together ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xxbos c' est en se posant les questions qui suivent au cours de l' étape de la mise en oeuvre que l' on pourra déterminer si les objectifs , les stratégies et les plans opérationnels établis à l' origine ont été bien xxunk : \\ par \\ pard { \\ pard { \\ pard \\ plain { \\ xxunk \\ pard \\ plain xxunk \\ xxunk \\ xxunk \\ xxunk \\ xxunk \\ xxunk \\ xxunk systèmes de soutien , les procédures , les contrôles et les examens des projets peuvent -ils être intégrés avec succès dans le processus de changement ?</td>\n",
       "      <td>xxbos whether the earlier objectives , strategies and operational plans were well - conceived will inevitably show up in the implementation stage in response to the following questions : \\ par \\ pard { \\ pard { \\ pard \\ plain { \\ xxunk \\ pard \\ plain xxunk \\ xxunk \\ xxunk \\ xxunk \\ xxunk \\ xxunk \\ xxunk supporting systems , procedures , project controls and reviews be successfully incorporated into the change process ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Check for average length of sentences"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# En\n",
    "m = np.array([len(st.split(\" \")) for st in df.to_numpy()[:, 0]])\n",
    "m.mean(), m.std()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(11.588159981655233, 6.950316044697761)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Fr\n",
    "n = np.array([len(st.split(\" \")) for st in df.to_numpy()[:, 1]])\n",
    "n.mean(), n.std()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(13.114998757906404, 8.258423695368164)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This might be a good baseline for how long you want your sequence length (`seq_len`) to be: the default 72 might be too long. Let's see how many **percentages of sentences** are at least 72 length. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "np.count_nonzero(m >= 72) / len(m) * 100, np.count_nonzero(n > 72) / len(n) * 100"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.03248552483231736, 0.06688196289006516)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Only 0.032% for English and 0.067% for French! This isn't a good sequence length to use, as we would have padding all over the place? \n",
    "\n",
    "However, one does notice that it seems like the sequence length for fastai v2 differs across batch (and same within batch). This might be the counter action that fastai v2 deal with different length, and variable sequence length method. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "model = Seq2SeqRNN_attn(emb_enc, emb_dec, 256, 30)\n",
    "learn = Learner(dls, model, loss_func=seq2seq_loss, \n",
    "                metrics=[seq2seq_acc, CorpusBLEUMetric(len(dls.vocab[1]))],\n",
    "                cbs=[TeacherForcing(30, 3)])\n",
    "learn.lr_find()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "SuggestedLRs(valley=tensor(0.0003))"
      ]
     },
     "metadata": {},
     "execution_count": 7
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "learn.fit_one_cycle(7, 2e-3)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>seq2seq_acc</th>\n",
       "      <th>corpus_bleu</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.267984</td>\n",
       "      <td>2.941255</td>\n",
       "      <td>0.587048</td>\n",
       "      <td>0.397089</td>\n",
       "      <td>02:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.432247</td>\n",
       "      <td>2.429537</td>\n",
       "      <td>0.637897</td>\n",
       "      <td>0.434980</td>\n",
       "      <td>02:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.510777</td>\n",
       "      <td>2.112346</td>\n",
       "      <td>0.674652</td>\n",
       "      <td>0.460755</td>\n",
       "      <td>02:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.059308</td>\n",
       "      <td>2.047936</td>\n",
       "      <td>0.683675</td>\n",
       "      <td>0.468946</td>\n",
       "      <td>02:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.099344</td>\n",
       "      <td>1.938624</td>\n",
       "      <td>0.697954</td>\n",
       "      <td>0.489107</td>\n",
       "      <td>02:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.067464</td>\n",
       "      <td>1.994792</td>\n",
       "      <td>0.692945</td>\n",
       "      <td>0.485352</td>\n",
       "      <td>02:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.176093</td>\n",
       "      <td>1.993718</td>\n",
       "      <td>0.693948</td>\n",
       "      <td>0.490502</td>\n",
       "      <td>02:28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "learn.save(Path(os.getcwd())/\"output/neural\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Path('/home/fastai2/notebooks/fastai_NLP/output/neural.pth')"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "learn.load(Path(os.getcwd())/\"output/neural\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<fastai.learner.Learner at 0x7fcf5c8164c0>"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here, the `xs`, `ys` and `zs` are our `inputs`, `targs` and `preds.argmax(1)` respectively, since they passed out as integers. Then, we get the str form, which are the `rxs`, `rys` and `rzs` by passing through our `GetPreds.get_predictions` function. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "inputs, preds, targs = learn.get_preds(with_input=True)\n",
    "p = GetPreds(dls, inputs[0], preds, targs)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "idx = 701\n",
    "rx, ry, rz = p.get_predictions(idx)\n",
    "x, y, z = inputs[0][idx], targs[idx], preds[idx]\n",
    "rx, ry, rz"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(\"xxbos quel est le nom du tribunal ou des juges qui ont pris la décision d' appel et le nombre d' appels ?\",\n",
       " 'xxbos what is the name of the court / judges who decided the xxunk ) and number of appeals ?',\n",
       " 'xxbos what is the name of the court or judges who have to appeal to ? the of positions ? xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad')"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def select_topk(outp, k=5):\n",
    "    probs = F.softmax(outp, dim=-1)\n",
    "    vals, idxs = probs.topk(k, dim=-1)\n",
    "    return idxs[torch.randint(k, (1,))]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "from random import choice\n",
    "\n",
    "def select_nucleus(outp, p=0.5):\n",
    "    probs = F.softmax(outp, dim=-1)\n",
    "    idxs = torch.argsort(probs, descending=True)\n",
    "    res, cumsum = [], 0\n",
    "\n",
    "    for idx in idxs:\n",
    "        res.append(idx)\n",
    "        cumsum += probs[idx]\n",
    "        if cumsum > p: return idxs.new_tensor([choice(res)])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "def decode(self, inp): \n",
    "    inp = inp[None]\n",
    "    bs, sl = inp.size()\n",
    "    hid, enc_out = self.encoder(bs, inp)\n",
    "    dec_inp = inp.new_zeros(bs).long() + self.bos_idx\n",
    "    enc_att = self.enc_att(enc_out)\n",
    "\n",
    "    res = []\n",
    "    for i in range(self.out_sl):\n",
    "        hid, outp = self.decoder(dec_inp, hid, enc_att, enc_out)\n",
    "        dec_inp = select_nucleus(outp[0], p=0.3)\n",
    "        # dec_inp = select_topk(outp[0], k=2)\n",
    "        res.append(dec_inp)\n",
    "        if (dec_inp == self.pad_idx).all(): break\n",
    "\n",
    "    return torch.cat(res)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "def predict_with_decode(learn, x, y):\n",
    "    learn.model.eval()\n",
    "    ds = learn.dls.train_ds\n",
    "    with torch.no_grad(): \n",
    "        try: out = decode(learn.model, x)\n",
    "        except Exception: out = decode(learn.model, x.cuda())\n",
    "        rx, ry, rz = p.get_predictions(idx)\n",
    "        # We overwrite rz since we don't need \"argmax\" anymore. \n",
    "        rz = itos(dls.vocab[1], out.cpu(), join=True, ignore_pad=True)\n",
    "    return rx, ry, rz"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "rx, ry, rz = predict_with_decode(learn, x, y)\n",
    "rz"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'xxbos what is the name of the court or court who decided to appeal and the number of appeal ?'"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.2",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit ('fastai': conda)"
  },
  "interpreter": {
   "hash": "5aa457f694240ca52bec53eda6ed84b45efde55787bbd717cb0e138c3a892911"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}